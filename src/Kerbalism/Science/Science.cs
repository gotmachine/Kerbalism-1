using System;
using System.Collections.Generic;
using System.Linq;
using System.Reflection;
using UnityEngine;


namespace KERBALISM
{

	public static class Science
	{
		// this controls how fast science is credited while it is being transmitted.
		// try to be conservative here, because crediting introduces a lag
		public const double buffer_science_value = 0.4; // min. 0.01 value
		public const long min_buffer_size = 81920; // min. 10kB
		public const long max_file_size = 9007199254740992; // max 1 PT (1024 TB)

		// this is for auto-transmit throttling
		public const double min_file_size = 0.002;

		private static readonly List<PendingProcess> processes = new List<PendingProcess>();
		private static readonly List<Result> results = new List<Result>();

		private class PendingProcess
		{
			public DataProcess process;
			public long dataPending;
			public long dataProcessed;
			public int convertingFromIndex;

			public PendingProcess(DataProcess process, long dataPending)
			{
				this.process = process;
				this.dataPending = dataPending;
				dataProcessed = 0;
				convertingFromIndex = -1;
			}
		}


		// pseudo-ctor
		public static void Init()
		{
			// make the science dialog invisible, just once
			if (Features.Science)
			{
				// TODO : fix the Hijacker
				//GameObject prefab = AssetBase.GetPrefab("ScienceResultsDialog");
				//if (Settings.ScienceDialog)
				//{
				//	prefab.gameObject.AddOrGetComponent<Hijacker>();
				//}
				//else
				//{
				//	prefab.gameObject.AddOrGetComponent<MiniHijacker>();
				//}

				// load EXPERIMENT_INFO nodes
				foreach (ConfigNode expNode in GameDatabase.Instance.GetConfigNodes("EXPERIMENT_INFO"))
				{
					ExperimentInfo exp_info = new ExperimentInfo(expNode);
					if (!exp_infos.ContainsKey(exp_info.id))
					{
						exp_infos.Add(exp_info.id, exp_info);

						foreach (ConfigNode varNode in expNode.GetNodes("VARIANT"))
						{
							ExperimentVariant exp_variant = new ExperimentVariant(varNode, exp_info);
							if (!exp_variants.ContainsKey(exp_variant.id))
								exp_variants.Add(exp_variant.id, exp_variant);
							else
								Lib.Log("WARNING : Duplicate VARIANT '" + exp_variant.id + "' wasn't loaded");
						}
					}
					else
						Lib.Log("WARNING : Duplicate EXPERIMENT_INFO '" + exp_info.id + "' wasn't loaded");
				}



				// build the biome index cache. the purpose of this is to allow fast checking of a biome availability using the biome object and its index.
				foreach (CelestialBody body in FlightGlobals.Bodies)
				{
					if (body.BiomeMap != null)
					{
						for (int i = 0; i < body.BiomeMap.Attributes.Length; i++)
						{
							biomes.Add(body.BiomeMap.Attributes[i], (byte)i);
						}
					}
						
				}

				// build the subject cache (megaloop !)
				// and get the data already retrieved in RnD
				//foreach (ExperimentInfo exp_info in exp_infos.Values)
				//{
				//	foreach (CelestialBody body in FlightGlobals.Bodies)
				//	{
				//		foreach (int sitInt in Enum.GetValues(typeof(KerbalismSituation)))
				//		{
				//			KerbalismSituation sit = (KerbalismSituation)sitInt;

				//			if (sit == KerbalismSituation.None) continue;

				//			if (exp_info.IsAvailable(sit, body))
				//			{
				//				if (!exp_info.BiomeIsRelevant(sit))
				//				{
				//					Subject subject = new Subject(exp_info, sit, body, string.Empty, true);
				//					subject.dataStoredRnD += subject.DataStoredInRnD();
				//					subjects.Add(subject.SubjectId, subject);
				//				}
				//				else
				//				{
				//					if (biomes.ContainsKey(body))
				//					{
				//						foreach (string biome in biomes[body])
				//						{
				//							Subject subject = new Subject(exp_info, sit, body, biome, true);
				//							subject.dataStoredRnD += subject.DataStoredInRnD();
				//							subjects.Add(subject.SubjectId, subject);
				//						}
				//					}

				//					// TODO : minibiomes doesn't work (exception because tying to add the same subjectId twice
				//					//if (exp_info.allowMiniBiomes)
				//					//{
				//					//	foreach (MiniBiome minibiome in body.MiniBiomes)
				//					//	{
				//					//		// TODO : Check that minibiome.GetTagKeyString is the right string
				//					//		Subject subject = new Subject(exp_info, sit, body, minibiome.GetTagKeyString, true);
				//					//		subject.dataStoredRnD += subject.DataStoredInRnD();
				//					//		subjects.Add(subject.SubjectId, subject);
				//					//	}
				//					//}
				//				}
				//			}
				//		}
				//	}
				//}

				// get the data stored in all drives from all vessels
				foreach (Drive drive in DB.drives.Values)
				{
					foreach (Result result in drive)
					{
						subjects[result.subjectId].dataStoredFlight += result.SizeWithBuffer;
					}
				}
			}
		}


		// Summary :
		// - get transmit capacity
		// - get all processes from the vessel
		// - foreach process, check conditions by calling CanRun()
		// - foreach valid process, get how much data can be generated by calling GetDataPending()
		//		- doing non-converter first
		//		- giving the value from non-converters to converters, so they can take it into account
		// - foreach process, doing converters first, try to transmit, then to store the data
		// - foreach process, call their Process() method, passing them how much data they did actually generate.
		// - if there is some transmit_capapcity left, try to transmit all the others files lying around
		// - trigger the science point crediting when the transmit buffers are full

		public static void Update(Vessel v, Vessel_info vi, VesselData vd, Vessel_resources resources, double elapsed_s)
		{
			// do nothing if science system is disabled
			if (!Features.Science) return;

			// get connection info and transmit capacity
			long transmitLeft;
			long transmitCapacity;

			ConnectionInfo conn = vi.connection;
			if (conn == null
				|| !conn.linked
				|| ResourceCache.Info(v, "ElectricCharge").amount < double.Epsilon)
				transmitCapacity = 0;
			else
				transmitCapacity = Lib.MBToBit(conn.rate * elapsed_s);

			transmitLeft = transmitCapacity;

			processes.Clear();
			results.Clear();

			// get all results from all drives :
			// - delete empty results
			// - reset the transmit/process rates
			// - build the list of results to be transmitted
			foreach (Drive drive in Drive.GetDrives(v))
			{
				for (int i = drive.Count - 1; i >= 0; i--)
				{
					// remove zero-size samples that didn't grow last time
					if (drive[i].type == FileType.Sample)
					{
						if (drive[i].Size == 0 && drive[i].processRate == 0)
							drive.RemoveAt(i);

						// for samples reset process rate and do nothing else
						drive[i].processRate = 0;
						continue;
					}

					// delete zero size files that didn't grow and weren't transmitted last time
					if (drive[i].Size == 0 && drive[i].processRate == 0 && drive[i].transmitRate == 0)
					{
						// credit the science value of the buffer
						if (drive[i].BufferSize > 0)
							Credit(drive[i], v.protoVessel, true);
						// TODO : send a "bool transmissionEnd = true" to Credit(), so it check the science value remaining and alert the player when subject is completed

						drive.RemoveAt(i);
						continue;
					}

					// we don't need the process rate anymore, reset it
					drive[i].processRate = 0;

					// if the file isn't flagged for transmission, reset the transmit rate
					if (!drive[i].process)
					{
						drive[i].transmitRate = 0;
						continue;
					}

					// file can be transmitted : add it the list
					results.Add(drive[i]);
				}
			}

			// sort results by the previous transmit rate, in ascending order
			// this way we will keep transferring the same results at each sim step
			// but priority will be given to newly generated results (they will be added at the end of the list)
			results.Sort((x, y) => x.transmitRate.CompareTo(y.transmitRate));

			// reset transmitRate now because it may be changed when transmitting process data
			for (int i = 0; i < results.Count; i++)
			{
				results[i].transmitRate = 0;
			}

			// get all processes that can generate data, and sort the list with converter processes first
			// note that all converters that can run are added, even if in the end they don't generate any data
			// we can't know yet because some data to be converted may be generated by non-converters
			int converterCount = 0;
			foreach (DataProcess p in DataProcess.GetProcesses(v))
			{
				if (p.PreUpdate(v, elapsed_s))
				{
					if (p.isConverter)
					{
						// keep track of converter count to use it in the for loops
						converterCount++;
						// insert converters at the top (zero data generated for now)
						processes.Insert(0, new PendingProcess(p, 0)); 
					}
					else
					{
						// only one non-converter process can run at once for the same subject
						foreach (PendingProcess pp in processes)
						{
							if (pp.process.Subject == p.Subject && pp.process.type == p.type)
							{
								Message.Post(Lib.BuildString("Experiment ", p.Subject.Title, " can't be running twice."), "One of the experiments has been stopped");
								p.running = false;
								goto continueOuter;
							}
						}

						// add non-converters and get how much data they can generate
						processes.Add(new PendingProcess(p, p.GetDataPending(v, elapsed_s)));
					}
				}
				continueOuter:;
			}

			// for each converter process, get dataPending that may by generated by non-converter processes
			// performance note : given the small amount of different processes that may be running at once
			// it is probably faster to iterate than trying to cache dataPending in the previous loop
			for (int i = 0; i < converterCount; i++)
			{
				// we don't get data from non-converter processes if auto-analyze is disabled and the result don't exist yet
				if (processes[i].process.convertedResult == null && !PreferencesScience.Instance.analyzeSamples)
					continue;

				long pendingDataToConvert = 0;

				// for each non-converter process
				for (int j = converterCount; j < processes.Count; j++)
				{
					// if the non-converter process is generating data that can be converted by the converter process
					if (processes[j].process.type == FileType.Sample
						&& processes[j].process.Subject.SubjectId == processes[i].process.Subject.SubjectId)
					{
						// the non converter process must have a result (that may stay empty), otherwise we can't get the Subject.
						// Note that this allow producing a sample even if there is no storage capacity left
						processes[j].process.CreateResult(v, 0);

						if (processes[j].process.result == null)
							break;

						// get the data amount that is generated by the non-converter process and remember its index
						processes[i].process.convertedResult = processes[j].process.result;
						pendingDataToConvert += processes[j].dataPending;
						processes[i].convertingFromIndex = j;
						break;
					}
				}
				processes[i].dataPending = processes[i].process.GetDataPending(v, elapsed_s, pendingDataToConvert);
			}

			// store and transmit data from processes, doing converters first
			for (int i = 0; i < processes.Count; i++)
			{
				// transmit if :
				// - there is some transmit capacity
				// - result is a file
				// - result is flagged for transfer or this is a new result and auto-transmit is true
				if (transmitLeft > 0
					&& processes[i].process.type == FileType.File
					&& ((processes[i].process.result != null && processes[i].process.result.process) // bad choice of var names, i agree...
						|| (processes[i].process.result == null && PreferencesScience.Instance.transmitScience)))
				{
					long transmitted = Math.Min(processes[i].dataPending, transmitLeft);
					if (transmitted > 0)
					{
						// Some data is transmitted so we need a result object for the transmit buffer
						// If no result exists, a new empty one is created (even if all drives ares full)
						if (processes[i].process.CreateResult(v, 0))
							results.Add(processes[i].process.result);

						// at this point if the result is null, either there are no drives or only private drives on the vessel
						if (processes[i].process.result != null)
						{
							transmitLeft -= transmitted;
							processes[i].dataPending -= transmitted;
							processes[i].dataProcessed += transmitted;
							processes[i].process.result.BufferSize += transmitted;
							processes[i].process.result.transmitRate += (long)(transmitted / elapsed_s);
							processes[i].process.result.processRate += (long)(transmitted / elapsed_s);
						}
					}
				}

				// we have transmitted all we can, now try storing the remaining data in drives
				while (processes[i].dataPending > 0)
				{
					// if we don't already have a result for this experiement,
					// find a drive with at least 1 bit of space available and create a new result
					processes[i].process.CreateResult(v, 1);

					// if no result : all drives are full, abort
					if (processes[i].process.result == null)
						break;

					// clamp data size to the drive available space
					long stored = Math.Min(processes[i].process.result.DriveCapacityAvailable(), processes[i].dataPending);

					// add data to the result and if the result has reached its max size,
					// let the loop continue so we can try to create another one
					if (processes[i].process.result.AddData(ref stored))
					{
						processes[i].process.result.processRate += (long)(stored / elapsed_s);
					}	
					else
					{
						processes[i].process.result.processRate += (long)(stored / elapsed_s);
						processes[i].process.result = null;
					}

					// if drive is now full, try to find another one
					if (stored < processes[i].dataPending)
						processes[i].process.result = null;

					// keep track of the data stored
					processes[i].dataPending -= stored;
					processes[i].dataProcessed += stored;
				}

				// update the data amount that exists for the subject on this vessel
				processes[i].process.existingData += processes[i].dataProcessed;

				// if there was not enough available space on drives, add the issue
				if (processes[i].dataProcessed <= 0)
					processes[i].process.issues.Add(processes[i].process.type == FileType.File ? "drive full" : "storage full");

				// tell the process to do its process-specific actions (consume resources, remove sample mass...)
				processes[i].process.PostUpdate(v, elapsed_s, processes[i].dataProcessed);

				// if this is a converter, update the converted result / process
				// note : dataProcessed is not accurate anymore after this
				if (i < converterCount)
				{
					long dataToRemove = 0;
					// are we converting data from a non-converter process ?
					if (processes[i].convertingFromIndex >= 0)
					{
						// clamp the amount to the non-converter production and update its data pending/processed
						dataToRemove = Math.Min(processes[processes[i].convertingFromIndex].dataPending, processes[i].dataProcessed);
						processes[processes[i].convertingFromIndex].dataPending -= dataToRemove;
						processes[processes[i].convertingFromIndex].dataProcessed += dataToRemove;
						processes[i].process.convertedResult.processRate += (long)(dataToRemove / elapsed_s);
						dataToRemove = processes[i].dataProcessed - dataToRemove;
					}
					// if we have processed more than what was generated by the process
					// then we converted some data from a preexisting Result
					if (processes[i].dataProcessed > dataToRemove)
					{
						processes[i].process.convertedResult.RemoveData(ref dataToRemove);
					}
				}
			}

			// if there is some transmit capacity left, transmit data stored in drives
			if (transmitLeft > 0)
			{
				// traversing in reverse because list is sorted with highest priority results last
				for (int i = results.Count - 1; i >= 0; i--)
				{
					if (results[i].Size <= 0) continue;
					long transmitted = results[i].Size < transmitLeft ? results[i].Size : transmitLeft;

					results[i].RemoveData(ref transmitted);
					results[i].BufferSize += transmitted;
					results[i].transmitRate += (long)(transmitted / elapsed_s);

					transmitLeft -= transmitted;
					if (transmitLeft <= 0) break;
				}
			}

			// avoid corner-case when RnD isn't live during scene changes
			// - this avoid losing science if the buffer reach threshold during a scene change
			// TODO : where to put this ?
			if (HighLogic.CurrentGame.Mode != Game.Modes.SANDBOX && ResearchAndDevelopment.Instance == null) return;

			// all file sizes are now updated
			// actually register data transmitted for files whose buffer is full
			for (int i = 0; i < results.Count; i++)
			{
				if (results[i].BufferSize > 0 && results[i].BufferSize > results[i].MaxBufferSize)
				{
					Credit(results[i], v.protoVessel, true);
					results[i].BufferSize = 0;
				}
			}

			//TODO : It is against the logic of the cache to update it from here, but for now I don't care
			vi.transmitting_rate = (long)((transmitCapacity - transmitLeft) / elapsed_s);
		}

		// return name of file being transmitted from vessel specified
		// TODO : adapt this, and see how we can adjust EC consumption
		public static string Transmitting(Vessel v, bool linked)
		{
			// never transmitting if science system is disabled
			if (!Features.Science) return string.Empty;

			// not transmitting if unlinked
			if (!linked) return string.Empty;

			// not transmitting if there is no ec left
			if (ResourceCache.Info(v, "ElectricCharge").amount <= double.Epsilon) return string.Empty;

			// no file flagged for transmission
			return string.Empty;
		}


		// credit science for the experiment subject specified
		// TODO : move this to a 100% event based implementation
		// OnScienceRecieved.Fire send the full list of every Result transmitted
		// then do the actual crediting once from the kerbalism main loop after every vessel Science.Update()
		public static float Credit(Result result, ProtoVessel pv, bool transmitOnly)
		{
			float credits;

			// try to get the stock subject from the stock scienceSubjects dictionary
			ScienceSubject subject = ResearchAndDevelopment.GetSubjectByID(result.subjectId);

			if(subject == null)
			{
				// if null, the stock subject doesn't exist yet. We have to create and add it.
				// get the private stock subjects dictionary
				var scienceSubjects = Lib.ReflectionValue<Dictionary<string, ScienceSubject>>
				(
				  ResearchAndDevelopment.Instance,
				  "scienceSubjects"
				);

				if (scienceSubjects != null)
				{
					subject = result.ParseToStockSubject(transmitOnly);
					credits = subject.science;
					scienceSubjects.Add(result.subjectId, subject);
				}
				else
				{
					Lib.Log("WARNING: science subject " + result.subjectId + " cannot be credited in R&D");
					return 0f;
				}
			}
			else
			{
				// the stock subject already exists : increase the science stored.
				credits = transmitOnly ?
				(float)result.ScienceValueBase(result.BufferSize) :
				(float)result.ScienceValueBase(result.Size + result.BufferSize);

				subject.science += credits;
				subject.scientificValue = ResearchAndDevelopment.GetSubjectValue(subject.science, subject);
			}

			// remove the data from our result
			result.BufferSize = 0;
			if (!transmitOnly)
				result.RemoveAllData();

			// apply the game difficulty factor :
			credits *= HighLogic.CurrentGame.Parameters.Career.ScienceGainMultiplier;
			// and finaly give the credits to the player
			ResearchAndDevelopment.Instance.AddScience(credits, transmitOnly ? TransactionReasons.ScienceTransmission : TransactionReasons.VesselRecovery);

			// fire game event
			// - this could be slow or a no-op, depending on the number of listeners
			//   in any case, we are buffering the transmitting data and calling this
			//   function only once in a while
			GameEvents.OnScienceRecieved.Fire(credits, subject, pv, false);

			// TODO : what is the purpose of having our own event ? 
			//API.OnScienceReceived.Fire(credits, subject, pv, transmitted);

			return credits;

			// TODO : message when subject is completed
			//			Message.Post(
			//				Lib.BuildString(Lib.HumanReadableScience(totalValue), " ", Experiment(exp_filename).FullName(exp_filename), " completed"),
			//			  Lib.TextVariant(
			//					"Our researchers will jump on it right now",
			//					"There is excitement because of your findings",
			//					"The results are causing a brouhaha in R&D"
			//				));
		}

		// return module acting as container of an experiment
		public static IScienceDataContainer Container(Part p, string experiment_id)
		{
			// first try to get a stock experiment module with the right experiment id
			// - this support parts with multiple experiment modules, like eva kerbal
			foreach (ModuleScienceExperiment exp in p.FindModulesImplementing<ModuleScienceExperiment>())
			{
				if (exp.experimentID == experiment_id) return exp;
			}

			// if none was found, default to the first module implementing the science data container interface
			// - this support third-party modules that implement IScienceDataContainer, but don't derive from ModuleScienceExperiment
			return p.FindModuleImplementing<IScienceDataContainer>();
		}

		/// <summary>
		/// return the ExperimentInfo object corresponding to a "experiment_id"
		/// </summary>
		public static ExperimentVariant GetExperimentVariant(string variant_id)
		{
			if (!exp_variants.ContainsKey(variant_id))
			{
				Lib.Log("ERROR: No ExperimentInfo found for id " + variant_id);
				return null;
			}
			return exp_variants[variant_id];
		}

		/// <summary>
		/// return the ExperimentInfo object corresponding to a "experiment_id"
		/// </summary>
		public static ExperimentInfo GetExperimentInfo(string experiment_id)
		{
			if (!exp_infos.ContainsKey(experiment_id))
			{
				Lib.Log("ERROR: No ExperimentInfo found for id " + experiment_id);
				return null;
			}
			return exp_infos[experiment_id];
		}

		/// <summary>
		/// return the ExperimentInfo object corresponding to a subject_id, formatted as "experiment_id@situation"
		/// </summary>
		public static ExperimentInfo GetExperimentInfoFromSubject(string subject_id)
		{
			return GetExperimentInfo(GetExperimentId(subject_id));
		}

		/// <summary>
		/// Get experiment id from a full subject id
		/// </summary>
		public static string GetExperimentId(string subject_id)
		{
			int i = subject_id.IndexOf('@');
			return i > 0 ? subject_id.Substring(0, i) : subject_id;
		}

		#region Global subject cache

		public static Subject GetSubjectFromCache(string subject_id)
		{
			if (subjects.ContainsKey(subject_id))
				return subjects[subject_id];

			return null;
		}

		// Remove all data stored in a drive from the global in-flight subject data cache
		public static void ClearFlightSubjectData(Drive drive)
		{
			for (int i = 0; i < drive.Count; i++)
			{
				AddFlightSubjectData(drive[i].subjectId, -drive[i].SizeWithBuffer);
			}
		}

		// Get stored data from the global in-flight subject data cache
		public static long GetFlightSubjectData(string subject_id)
		{ return subjects.ContainsKey(subject_id) ? subjects[subject_id].dataStoredFlight : 0; }

		// Add data/remove data from the global in-flight subject data cache
		public static void AddFlightSubjectData(string subject_id, long amount)
		{
			if (subjects.ContainsKey(subject_id))
				subjects[subject_id].dataStoredFlight += amount;

		#if DEBUG
			if (subjects.ContainsKey(subject_id) && subjects[subject_id].dataStoredFlight < 0)
			{
				Lib.DebugLog("WARNING : for Subject " + subject_id + " dataStoredFlight is negative : " + subjects[subject_id].dataStoredFlight);
			}
		#endif

		}

		#endregion

		#region Experiments utils


		// TODO : migrate to ExperimentVariant
		public static string RequirementText(string requirement)
		{
			var parts = Lib.Tokenize(requirement, ':');

			var condition = parts[0];
			string value = string.Empty;
			if (parts.Count > 1) value = parts[1];
						
			switch (condition)
			{
				case "OrbitMinInclination": return Lib.BuildString("Min. inclination ", value, "°");
				case "OrbitMaxInclination": return Lib.BuildString("Max. inclination ", value, "°");
				case "OrbitMinEccentricity": return Lib.BuildString("Min. eccentricity ", value);
				case "OrbitMaxEccentricity": return Lib.BuildString("Max. eccentricity ", value);
				case "OrbitMinArgOfPeriapsis": return Lib.BuildString("Min. argument of Pe ", value);
				case "OrbitMaxArgOfPeriapsis": return Lib.BuildString("Max. argument of Pe ", value);
				case "AltitudeMin": return Lib.BuildString("Min. altitude ", Lib.HumanReadableRange(Double.Parse(value)));
				case "AltitudeMax":
					var v = Double.Parse(value);
					if (v >= 0) return Lib.BuildString("Max. altitude ", Lib.HumanReadableRange(v));
					return Lib.BuildString("Min. depth ", Lib.HumanReadableRange(-v));
				case "RadiationMin": return Lib.BuildString("Min. radiation ", Lib.HumanReadableRadiation(Double.Parse(value)));
				case "RadiationMax": return Lib.BuildString("Max. radiation ", Lib.HumanReadableRadiation(Double.Parse(value)));
				case "Body": return PrettyBodyText(value);
				case "TemperatureMin": return Lib.BuildString("Min. temperature ", Lib.HumanReadableTemp(Double.Parse(value)));
				case "TemperatureMax": return Lib.BuildString("Max. temperature ", Lib.HumanReadableTemp(Double.Parse(value)));
				case "CrewMin": return Lib.BuildString("Min. crew ", value);
				case "CrewMax": return Lib.BuildString("Max. crew ", value);
				case "CrewCapacityMin": return Lib.BuildString("Min. crew capacity ", value);
				case "CrewCapacityMax": return Lib.BuildString("Max. crew capacity ", value);
				case "VolumePerCrewMin": return Lib.BuildString("Min. vol./crew ", Lib.HumanReadableVolume(double.Parse(value)));
				case "VolumePerCrewMax": return Lib.BuildString("Max. vol./crew ", Lib.HumanReadableVolume(double.Parse(value)));
				case "MaxAsteroidDistance": return Lib.BuildString("Max. asteroid distance ", Lib.HumanReadableRange(double.Parse(value)));

				case "AtmosphereBody": return "Body with atmosphere";
				case "AtmosphereAltMin": return Lib.BuildString("Min. atmosphere altitude ", value);
				case "AtmosphereAltMax": return Lib.BuildString("Max. atmosphere altitude ", value);
					
				case "SurfaceSpeedMin": return Lib.BuildString("Min. surface speed ", Lib.HumanReadableSpeed(double.Parse(value)));
				case "SurfaceSpeedMax": return Lib.BuildString("Max. surface speed ", Lib.HumanReadableSpeed(double.Parse(value)));
				case "VerticalSpeedMin": return Lib.BuildString("Min. vertical speed ", Lib.HumanReadableSpeed(double.Parse(value)));
				case "VerticalSpeedMax": return Lib.BuildString("Max. vertical speed ", Lib.HumanReadableSpeed(double.Parse(value)));
				case "SpeedMin": return Lib.BuildString("Min. speed ", Lib.HumanReadableSpeed(double.Parse(value)));
				case "SpeedMax": return Lib.BuildString("Max. speed ", Lib.HumanReadableSpeed(double.Parse(value)));
				case "DynamicPressureMin": return Lib.BuildString("Min. dynamic pressure ", Lib.HumanReadablePressure(double.Parse(value)));
				case "DynamicPressureMax": return Lib.BuildString("Max. dynamic pressure ", Lib.HumanReadablePressure(double.Parse(value)));
				case "StaticPressureMin": return Lib.BuildString("Min. pressure ", Lib.HumanReadablePressure(double.Parse(value)));
				case "StaticPressureMax": return Lib.BuildString("Max. pressure ", Lib.HumanReadablePressure(double.Parse(value)));
				case "AtmDensityMin": return Lib.BuildString("Min. atm. density ", Lib.HumanReadablePressure(double.Parse(value)));
				case "AtmDensityMax": return Lib.BuildString("Max. atm. density ", Lib.HumanReadablePressure(double.Parse(value)));
				case "AltAboveGroundMin": return Lib.BuildString("Min. ground altitude ", Lib.HumanReadableRange(double.Parse(value)));
				case "AltAboveGroundMax": return Lib.BuildString("Max. ground altitude ", Lib.HumanReadableRange(double.Parse(value)));

				case "MissionControlLevelMin": return Lib.BuildString(ScenarioUpgradeableFacilities.GetFacilityName(SpaceCenterFacility.MissionControl), " level ", value);
				case "MissionControlLevelMax": return Lib.BuildString(ScenarioUpgradeableFacilities.GetFacilityName(SpaceCenterFacility.MissionControl), " max. level ", value);
				case "AdministrationLevelMin": return Lib.BuildString(ScenarioUpgradeableFacilities.GetFacilityName(SpaceCenterFacility.Administration), " level ", value);
				case "AdministrationLevelMax": return Lib.BuildString(ScenarioUpgradeableFacilities.GetFacilityName(SpaceCenterFacility.Administration), " max. level ", value);
				case "TrackingStationLevelMin": return Lib.BuildString(ScenarioUpgradeableFacilities.GetFacilityName(SpaceCenterFacility.TrackingStation), " level ", value);
				case "TrackingStationLevelMax": return Lib.BuildString(ScenarioUpgradeableFacilities.GetFacilityName(SpaceCenterFacility.TrackingStation), " max. level ", value);
				case "AstronautComplexLevelMin": return Lib.BuildString(ScenarioUpgradeableFacilities.GetFacilityName(SpaceCenterFacility.AstronautComplex), " level ", value);
				case "AstronautComplexLevelMax": return Lib.BuildString(ScenarioUpgradeableFacilities.GetFacilityName(SpaceCenterFacility.AstronautComplex), " max. level ", value);

				case "Part": return Lib.BuildString("Needs part ", value);
				case "Module": return Lib.BuildString("Needs module ", value);

				default:
					return Lib.SpacesOnCaps(condition);
			}
		}

		public static string PrettyBodyText(string requires)
		{
			string result = "";
			foreach(var s in Lib.Tokenize(requires, ';'))
			{
				if (result.Length > 0) result += ", ";
				if (s[0] == '!') result += "not " + s.Substring(1);
				else result += s;
			}
			return result;
		}

		#endregion


		// return the index of a biome attribute object in the CelestialBody.BiomeMap.Attributes array
		public static int GetBiomeIndex(CBAttributeMapSO.MapAttribute biome)
		{
			// note : checking for containkey is useless : if the biome isn't in the dictionary, we have a very big problem anyway
			return biomes[biome];
		}
		

		// experiment info 
		private static readonly Dictionary<string, ExperimentInfo> exp_infos = new Dictionary<string, ExperimentInfo>();
		private static readonly Dictionary<string, ExperimentVariant> exp_variants = new Dictionary<string, ExperimentVariant>();
		private static readonly Dictionary<string, Subject> subjects = new Dictionary<string, Subject>();
		private static readonly Dictionary<CBAttributeMapSO.MapAttribute, byte> biomes = new Dictionary<CBAttributeMapSO.MapAttribute, byte>();

	}

} // KERBALISM

